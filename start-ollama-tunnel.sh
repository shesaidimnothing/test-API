#!/bin/bash
# Script bash pour dÃ©marrer Ollama avec tunnel
# ExÃ©cuter: chmod +x start-ollama-tunnel.sh && ./start-ollama-tunnel.sh

echo "ğŸš€ DÃ©marrage d'Ollama avec tunnel..."

# Configuration Ollama pour accepter les connexions externes
export OLLAMA_HOST="0.0.0.0:11434"
echo "âœ… Configuration Ollama: $OLLAMA_HOST"

# DÃ©marrer Ollama en arriÃ¨re-plan
echo "ğŸ”„ DÃ©marrage d'Ollama..."
ollama serve &
OLLAMA_PID=$!

# Attendre que Ollama soit prÃªt
echo "â³ Attente du dÃ©marrage d'Ollama..."
sleep 10

# VÃ©rifier que Ollama fonctionne
if curl -s http://localhost:11434/api/tags > /dev/null; then
    echo "âœ… Ollama est prÃªt !"
    MODEL_COUNT=$(curl -s http://localhost:11434/api/tags | jq '.models | length' 2>/dev/null || echo "?")
    echo "ğŸ“‹ ModÃ¨les disponibles: $MODEL_COUNT"
else
    echo "âŒ Erreur: Ollama n'est pas accessible"
    echo "ğŸ’¡ VÃ©rifiez que Ollama est installÃ© et configurÃ©"
    kill $OLLAMA_PID 2>/dev/null
    exit 1
fi

# Fonction de nettoyage
cleanup() {
    echo "ğŸ›‘ ArrÃªt des services..."
    kill $OLLAMA_PID 2>/dev/null
    pkill -f ngrok 2>/dev/null
    exit 0
}

# Capturer Ctrl+C
trap cleanup SIGINT SIGTERM

# DÃ©marrer ngrok
echo "ğŸŒ DÃ©marrage du tunnel ngrok..."
echo "ğŸ“ Note: Gardez ce terminal ouvert pour maintenir le tunnel"
echo "ğŸ”— L'URL du tunnel sera affichÃ©e ci-dessous"

# DÃ©marrer ngrok en arriÃ¨re-plan
ngrok http 11434 --host-header=localhost:11434 &
NGROK_PID=$!

echo "âœ… Tunnel dÃ©marrÃ© !"
echo "ğŸ“‹ Prochaines Ã©tapes:"
echo "   1. Copiez l'URL ngrok (ex: https://abc123.ngrok.io)"
echo "   2. Ajoutez-la comme variable OLLAMA_TUNNEL_URL sur Vercel"
echo "   3. RedÃ©ployez votre application Vercel"
echo "   4. Testez l'IA sur votre site Vercel"

echo ""
echo "ğŸ›‘ Pour arrÃªter: Ctrl+C"
echo ""

# Attendre indÃ©finiment
while true; do
    sleep 1
done
