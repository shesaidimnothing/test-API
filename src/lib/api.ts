// Utilitaires API pour l'intégration des modèles IA
// Ce fichier sera utilisé pour intégrer de vrais modèles IA et des APIs

// Interface pour un message de chat
export interface ChatMessage {
  id: string;
  content: string;
  role: "user" | "assistant";
  timestamp: Date;
}

// Interface pour une requête de chat
export interface ChatRequest {
  messages: ChatMessage[];
  model?: string;
  temperature?: number;
  maxTokens?: number;
}

// Interface pour une réponse de chat
export interface ChatResponse {
  message: ChatMessage;
  usage?: {
    promptTokens: number;
    completionTokens: number;
    totalTokens: number;
  };
}

// Classe de service IA pour l'intégration future des APIs
export class AIService {
  private apiKey: string;
  private baseUrl: string;

  constructor(apiKey: string, baseUrl: string = "https://api.openai.com/v1") {
    this.apiKey = apiKey;
    this.baseUrl = baseUrl;
  }

  // Méthode pour envoyer un message et recevoir une réponse
  async sendMessage(request: ChatRequest): Promise<ChatResponse> {
    // TODO: Implémenter un vrai appel API vers le modèle IA
    // Ceci est un placeholder qui simule un appel API
    
    // Simulation du délai API
    await new Promise(resolve => setTimeout(resolve, 1000 + Math.random() * 2000));
    
    // Génération d'une réponse simulée basée sur le message de l'utilisateur
    const lastMessage = request.messages[request.messages.length - 1];
    const mockResponse = this.generateMockResponse(lastMessage.content);
    
    return {
      message: {
        id: Date.now().toString(),
        content: mockResponse,
        role: "assistant",
        timestamp: new Date(),
      },
      usage: {
        promptTokens: lastMessage.content.length / 4, // Estimation approximative
        completionTokens: mockResponse.length / 4,
        totalTokens: (lastMessage.content.length + mockResponse.length) / 4,
      }
    };
  }

  // Méthode privée pour générer une réponse simulée
  private generateMockResponse(userMessage: string): string {
    const responses = [
      "I understand your question. This is a placeholder response that will be replaced with actual AI model responses once the API integration is complete.",
      "That's an interesting point. The AI model integration is currently being set up, so this is just a demo response.",
      "I'd be happy to help with that! Once the real AI model is connected, I'll be able to provide more detailed and accurate responses.",
      "Great question! This response is generated by a placeholder system. The actual AI model will provide much more sophisticated answers.",
      "I see what you're asking about. The current system is just a demo - the real AI integration will be much more powerful.",
    ];
    
    // Sélection de réponse basée sur des mots-clés simples
    const message = userMessage.toLowerCase();
    if (message.includes("hello") || message.includes("hi")) {
      return "Hello! I'm your AI assistant. This is a demo response - the real AI model will be connected soon!";
    } else if (message.includes("help")) {
      return "I'm here to help! This is currently a demo version. Once the AI model is integrated, I'll be able to assist you with a wide range of tasks.";
    } else if (message.includes("code") || message.includes("programming")) {
      return "I can help with programming questions! This demo response will be replaced with actual code assistance once the AI model is connected.";
    } else if (message.includes("weather")) {
      return "I can help with weather information! The real AI model will be able to provide current weather data and forecasts.";
    } else {
      return responses[Math.floor(Math.random() * responses.length)];
    }
  }
}

// Configuration pour différents modèles IA
export const AI_MODELS = {
  GPT_4: "gpt-4",
  GPT_3_5_TURBO: "gpt-3.5-turbo",
  CLAUDE_3_OPUS: "claude-3-opus-20240229",
  CLAUDE_3_SONNET: "claude-3-sonnet-20240229",
  CLAUDE_3_HAIKU: "claude-3-haiku-20240307",
} as const;

export type AIModel = typeof AI_MODELS[keyof typeof AI_MODELS];

// Configuration par défaut
export const DEFAULT_CONFIG = {
  model: AI_MODELS.GPT_3_5_TURBO,
  temperature: 0.7,
  maxTokens: 2000,
} as const;
