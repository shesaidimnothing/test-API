// API utilities for AI model integration
// This file will be used to integrate with real AI models and APIs

export interface ChatMessage {
  id: string;
  content: string;
  role: "user" | "assistant";
  timestamp: Date;
}

export interface ChatRequest {
  messages: ChatMessage[];
  model?: string;
  temperature?: number;
  maxTokens?: number;
}

export interface ChatResponse {
  message: ChatMessage;
  usage?: {
    promptTokens: number;
    completionTokens: number;
    totalTokens: number;
  };
}

// Placeholder for future AI API integration
export class AIService {
  private apiKey: string;
  private baseUrl: string;

  constructor(apiKey: string, baseUrl: string = "https://api.openai.com/v1") {
    this.apiKey = apiKey;
    this.baseUrl = baseUrl;
  }

  async sendMessage(request: ChatRequest): Promise<ChatResponse> {
    // TODO: Implement actual API call to AI model
    // This is a placeholder that simulates an API call
    
    // Simulate API delay
    await new Promise(resolve => setTimeout(resolve, 1000 + Math.random() * 2000));
    
    // Generate a mock response based on the user's message
    const lastMessage = request.messages[request.messages.length - 1];
    const mockResponse = this.generateMockResponse(lastMessage.content);
    
    return {
      message: {
        id: Date.now().toString(),
        content: mockResponse,
        role: "assistant",
        timestamp: new Date(),
      },
      usage: {
        promptTokens: lastMessage.content.length / 4, // Rough estimation
        completionTokens: mockResponse.length / 4,
        totalTokens: (lastMessage.content.length + mockResponse.length) / 4,
      }
    };
  }

  private generateMockResponse(userMessage: string): string {
    const responses = [
      "I understand your question. This is a placeholder response that will be replaced with actual AI model responses once the API integration is complete.",
      "That's an interesting point. The AI model integration is currently being set up, so this is just a demo response.",
      "I'd be happy to help with that! Once the real AI model is connected, I'll be able to provide more detailed and accurate responses.",
      "Great question! This response is generated by a placeholder system. The actual AI model will provide much more sophisticated answers.",
      "I see what you're asking about. The current system is just a demo - the real AI integration will be much more powerful.",
    ];
    
    // Simple keyword-based response selection
    const message = userMessage.toLowerCase();
    if (message.includes("hello") || message.includes("hi")) {
      return "Hello! I'm your AI assistant. This is a demo response - the real AI model will be connected soon!";
    } else if (message.includes("help")) {
      return "I'm here to help! This is currently a demo version. Once the AI model is integrated, I'll be able to assist you with a wide range of tasks.";
    } else if (message.includes("code") || message.includes("programming")) {
      return "I can help with programming questions! This demo response will be replaced with actual code assistance once the AI model is connected.";
    } else if (message.includes("weather")) {
      return "I can help with weather information! The real AI model will be able to provide current weather data and forecasts.";
    } else {
      return responses[Math.floor(Math.random() * responses.length)];
    }
  }
}

// Configuration for different AI models
export const AI_MODELS = {
  GPT_4: "gpt-4",
  GPT_3_5_TURBO: "gpt-3.5-turbo",
  CLAUDE_3_OPUS: "claude-3-opus-20240229",
  CLAUDE_3_SONNET: "claude-3-sonnet-20240229",
  CLAUDE_3_HAIKU: "claude-3-haiku-20240307",
} as const;

export type AIModel = typeof AI_MODELS[keyof typeof AI_MODELS];

// Default configuration
export const DEFAULT_CONFIG = {
  model: AI_MODELS.GPT_3_5_TURBO,
  temperature: 0.7,
  maxTokens: 2000,
} as const;
